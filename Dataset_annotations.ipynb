{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0c_BxmQvKKY",
        "outputId": "653b3582-eb70-4a9e-be61-d497b3c7cc52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers pandas pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llx0tgwZVJa1",
        "outputId": "e7d45fa0-d953-4ba4-d244-5f663db22de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOYE9jbsvjIB",
        "outputId": "79bbab3f-dd8e-4e74-97b0-a7f3dd607652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descriptions saved to annotations.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "# Load BLIP model and processor\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "\n",
        "# Folder containing images\n",
        "image_folder = \"/content/drive/MyDrive/Trial_dataset\"\n",
        "output_csv = \"annotations.csv\"\n",
        "\n",
        "# Initialize results list\n",
        "results = []\n",
        "\n",
        "# Process images\n",
        "for img_file in os.listdir(image_folder):\n",
        "    if img_file.endswith(('.png', '.jpg', '.jpeg')):\n",
        "        img_path = os.path.join(image_folder, img_file)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Generate caption\n",
        "        inputs = processor(images=image, return_tensors=\"pt\")\n",
        "        outputs = model.generate(**inputs)\n",
        "        caption = processor.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # Append to results\n",
        "        results.append({\"filename\": img_file, \"description\": caption})\n",
        "\n",
        "# Save to CSV\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(output_csv, index=False)\n",
        "\n",
        "print(f\"Descriptions saved to {output_csv}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for result in results:\n",
        "    description = result[\"description\"]\n",
        "    query = f\"What is in the image described as: '{description}'?\"\n",
        "    result[\"query\"] = query"
      ],
      "metadata": {
        "id": "d1d8rGqtZVrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool\n",
        "\n",
        "def process_image(img_file):\n",
        "    # Load and process image, generate description and query\n",
        "    image = Image.open(img_file).convert(\"RGB\")\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "    outputs = model.generate(**inputs)\n",
        "    caption = processor.decode(outputs[0], skip_special_tokens=True)\n",
        "    query = f\"What is in the image described as: '{caption}'?\"\n",
        "    return {\"filename\": img_file, \"description\": caption, \"query\": query}\n",
        "\n",
        "# Path to images\n",
        "image_folder = \"/content/drive/MyDrive/Trial_dataset\"\n",
        "image_paths = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "# Process images in parallel\n",
        "with Pool(processes=4) as pool:  # Adjust process count based on system resources\n",
        "    results = pool.map(process_image, image_paths)\n",
        "\n",
        "# Save to CSV\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(output_csv, index=False)\n"
      ],
      "metadata": {
        "id": "cBRUOLjhZau0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save DataFrame to CSV\n",
        "df.to_csv(\"annotations.csv\", index=False)"
      ],
      "metadata": {
        "id": "hOEJSc9bZdvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Convert DataFrame to dictionary\n",
        "data_dict = df.to_dict(orient=\"records\")\n",
        "\n",
        "# Save as JSON\n",
        "with open(\"annotations.json\", \"w\") as json_file:\n",
        "    json.dump(data_dict, json_file, indent=4)\n",
        "\n",
        "print(\"Annotations saved to annotations.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqQAelL1ZgHF",
        "outputId": "50c24d27-e5a6-4596-e694-b45d30222760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annotations saved to annotations.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load JSON to verify\n",
        "with open(\"annotations.json\", \"r\") as json_file:\n",
        "    annotations = json.load(json_file)\n",
        "\n",
        "print(annotations[:5])  # Print the first 5 entries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETbLmSCXZiWn",
        "outputId": "eca4c8ee-2cb1-4bb1-cc87-fa34cbaabb25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'filename': '/content/drive/MyDrive/Trial_dataset/118.png', 'description': 'a man in camouflage clothing holding a rifle', 'query': \"What is in the image described as: 'a man in camouflage clothing holding a rifle'?\"}, {'filename': '/content/drive/MyDrive/Trial_dataset/Automatic Rifle_16.png', 'description': 'a gun with a barrel and a barrel', 'query': \"What is in the image described as: 'a gun with a barrel and a barrel'?\"}, {'filename': '/content/drive/MyDrive/Trial_dataset/111.png', 'description': 'a soldier with a gun in his hand stock photo', 'query': \"What is in the image described as: 'a soldier with a gun in his hand stock photo'?\"}, {'filename': '/content/drive/MyDrive/Trial_dataset/112.png', 'description': 'a man in camouflage clothing holding a rifle', 'query': \"What is in the image described as: 'a man in camouflage clothing holding a rifle'?\"}, {'filename': '/content/drive/MyDrive/Trial_dataset/110.png', 'description': 'a man in a black suit and helmet with a gun', 'query': \"What is in the image described as: 'a man in a black suit and helmet with a gun'?\"}]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}